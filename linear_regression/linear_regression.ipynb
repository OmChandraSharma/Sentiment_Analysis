{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZJJA54bGtrffwMwY5GO+R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OmChandraSharma/Sentiment_Analysis/blob/main/linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osWLgtEfOliD",
        "outputId": "5c3b14d4-2712-4bef-9d77-0983c0626728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=133jd-yMyIpnVnHPYjiopu0XlpDk6I_H3\n",
            "From (redirected): https://drive.google.com/uc?id=133jd-yMyIpnVnHPYjiopu0XlpDk6I_H3&confirm=t&uuid=a26ecaf4-c9c0-4880-9744-cdce9cd04b59\n",
            "To: /content/clean_data.csv\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212M/212M [00:03<00:00, 56.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   polarity  id                          date    query      user  \\\n",
            "0         4   3  Mon May 11 03:17:40 UTC 2009  kindle2    tpryan   \n",
            "1         4   4  Mon May 11 03:18:03 UTC 2009  kindle2    vcu451   \n",
            "2         4   5  Mon May 11 03:18:54 UTC 2009  kindle2    chadfu   \n",
            "3         4   6  Mon May 11 03:19:04 UTC 2009  kindle2     SIX15   \n",
            "4         4   7  Mon May 11 03:21:41 UTC 2009  kindle2  yamarama   \n",
            "\n",
            "                                                text       source sentiment  \\\n",
            "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...  manual_test  positive   \n",
            "1  Reading my kindle2...  Love it... Lee childs i...  manual_test  positive   \n",
            "2  Ok, first assesment of the #kindle2 ...it fuck...  manual_test  positive   \n",
            "3  @kenburbary You'll love your Kindle2. I've had...  manual_test  positive   \n",
            "4  @mikefish  Fair enough. But i have the Kindle2...  manual_test  positive   \n",
            "\n",
            "                                          clean_text  \n",
            "0  loooooooovvvvvveee kindle2 dx cool 2 fantastic...  \n",
            "1           reading kindle2 love lee child good read  \n",
            "2                    ok first assesment fucking rock  \n",
            "3  youll love kindle2 ive mine month never looked...  \n",
            "4                  fair enough kindle2 think perfect  \n",
            "ðŸ“ Loaded data with shape: (1044205, 9)\n",
            "âœ… Model trained and saved.\n",
            "ðŸ“‰ Mean Squared Error: 0.3496\n",
            "ðŸ“ˆ RÂ² Score: 0.5167\n",
            "ðŸ“Š Graphs saved under: /content/drive/MyDrive/sentiment_regression_pipeline/artifacts/plots\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "# Define a working directory within your Drive\n",
        "WORKING_DIR = \"/content/drive/MyDrive/sentiment_regression_pipeline\"\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(WORKING_DIR, exist_ok=True)\n",
        "\n",
        "# === CONFIG ===\n",
        "BASE_DIR = \"/content/drive/MyDrive/sentiment_regression_pipeline\"\n",
        "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
        "MODEL_DIR = os.path.join(BASE_DIR, \"artifacts/models\")\n",
        "VECTORIZER_DIR = os.path.join(BASE_DIR, \"artifacts/vectorizers\")\n",
        "ENCODER_DIR = os.path.join(BASE_DIR, \"artifacts/encoders\")\n",
        "PLOTS_DIR = os.path.join(BASE_DIR, \"artifacts/plots\")\n",
        "\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(VECTORIZER_DIR, exist_ok=True)\n",
        "os.makedirs(ENCODER_DIR, exist_ok=True)\n",
        "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
        "\n",
        "# === STEP 1: Load Data ===\n",
        "!pip install -q gdown\n",
        "import gdown\n",
        "\n",
        "# Download using the file ID\n",
        "file_id = \"133jd-yMyIpnVnHPYjiopu0XlpDk6I_H3\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", \"clean_data.csv\", quiet=False)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"clean_data.csv\")\n",
        "print(df.head())\n",
        "df = df.dropna(subset=[\"clean_text\", \"sentiment\"])\n",
        "df.to_csv(os.path.join(DATA_DIR, \"clean_data.csv\"), index=False)\n",
        "print(f\"ðŸ“ Loaded data with shape: {df.shape}\")\n",
        "\n",
        "# === STEP 2: TF-IDF Vectorization ===\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X = tfidf_vectorizer.fit_transform(df[\"clean_text\"])\n",
        "\n",
        "joblib.dump(tfidf_vectorizer, os.path.join(VECTORIZER_DIR, \"tfidf_vectorizer.pkl\"))\n",
        "\n",
        "# === STEP 3: Label Encoding ===\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df[\"sentiment\"])\n",
        "\n",
        "joblib.dump(label_encoder, os.path.join(ENCODER_DIR, \"label_encoder.pkl\"))\n",
        "\n",
        "# === STEP 4: Train Model ===\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "joblib.dump(model, os.path.join(MODEL_DIR, \"linear_regression_model.pkl\"))\n",
        "\n",
        "# === STEP 5: Evaluation ===\n",
        "y_pred = model.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "print(\"âœ… Model trained and saved.\")\n",
        "print(f\"ðŸ“‰ Mean Squared Error: {mse:.4f}\")\n",
        "print(f\"ðŸ“ˆ RÂ² Score: {r2:.4f}\")\n",
        "\n",
        "# === STEP 6: Save Evaluation Plots ===\n",
        "\n",
        "# Scatter plot: Actual vs Predicted\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y, y_pred, alpha=0.4, color=\"blue\", edgecolor=\"k\")\n",
        "plt.xlabel(\"Actual Sentiment (Encoded)\")\n",
        "plt.ylabel(\"Predicted Sentiment\")\n",
        "plt.title(\"Actual vs Predicted Sentiment (Linear Regression)\")\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(PLOTS_DIR, \"actual_vs_predicted.png\"))\n",
        "plt.close()\n",
        "\n",
        "# Residual plot\n",
        "residuals = y - y_pred\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(residuals, bins=30, color='orange', edgecolor='black')\n",
        "plt.title(\"Residuals Histogram\")\n",
        "plt.xlabel(\"Residual (Actual - Predicted)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(PLOTS_DIR, \"residuals_histogram.png\"))\n",
        "plt.close()\n",
        "\n",
        "# Line plot: Error vs Sample Index\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(residuals, linestyle='-', color='red')\n",
        "plt.title(\"Residuals Across Samples\")\n",
        "plt.xlabel(\"Sample Index\")\n",
        "plt.ylabel(\"Residual\")\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join(PLOTS_DIR, \"residuals_lineplot.png\"))\n",
        "plt.close()\n",
        "\n",
        "print(\"ðŸ“Š Graphs saved under:\", PLOTS_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Round predictions to nearest integer to simulate classification\n",
        "y_pred_rounded = y_pred.round().astype(int)\n",
        "\n",
        "# Clip predictions to stay within valid class range\n",
        "y_pred_rounded = y_pred_rounded.clip(min=0, max=len(label_encoder.classes_) - 1)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y, y_pred_rounded)\n",
        "\n",
        "print(f\"ðŸŽ¯ Approximate Classification Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxat2XoGaV0U",
        "outputId": "41b631a7-40ef-4401-bfad-6d70ed048c43"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Approximate Classification Accuracy: 68.42%\n"
          ]
        }
      ]
    }
  ]
}